{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "8cce02fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durbin-Watson statistic:  2.001082570957702\n",
      "There is autocorrelation in the data, the model is likely non-linear\n",
      "RMSE: 0.4983541724976178\n",
      "R2 score:  0.5273482148664972\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import make_scorer\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import *\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "\n",
    "# Load the data\n",
    "df_train = pd.read_csv('train_descriptors.csv')\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "df_train = df_train.drop(columns=[\"Compound No.\",\"SMILES\",\"logP\",\"ring_count\"])\n",
    "# Extract the \"MW\" column\n",
    "MW = df_train[\"MW\"]\n",
    "\n",
    "# Min-Max normalization\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "MW_normalized = min_max_scaler.fit_transform(MW.values.reshape(-1,1))\n",
    "\n",
    "# Add the normalized column back to the dataframe\n",
    "df_train[\"MW\"] = MW_normalized\n",
    "# Extract the \"MW\" column\n",
    "TPSA = df_train[\"TPSA\"]\n",
    "\n",
    "# Min-Max normalization\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "TPSA_normalized = min_max_scaler.fit_transform(TPSA.values.reshape(-1,1))\n",
    "\n",
    "# Add the normalized column back to the dataframe\n",
    "df_train[\"TPSA\"] = TPSA_normalized\n",
    "# Split the training data into features and labels\n",
    "X_train = df_train.drop(columns=['pIC50 (IC50 in microM)'])\n",
    "y_train = df_train['pIC50 (IC50 in microM)']\n",
    "\n",
    "X_train.to_csv('submission_to_submit3.csv', index=False)\n",
    "def preprocess_data(X):\n",
    "  imputer = SimpleImputer(strategy='mean')\n",
    "  X = imputer.fit_transform(X)\n",
    "  return X\n",
    "# Preprocess the data\n",
    "X_train = preprocess_data(X_train)\n",
    "X_train1=X_train\n",
    "y_train1=y_train\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,test_size=0.2, random_state=0)\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "# Fit a linear regression model to the data\n",
    "model = OLS(y_train, X_train).fit()\n",
    "\n",
    "# Perform the Durbin-Watson test\n",
    "dw_stat = durbin_watson(model.resid)\n",
    "\n",
    "# Print the Durbin-Watson statistic\n",
    "print(\"Durbin-Watson statistic: \", dw_stat)\n",
    "\n",
    "# Check for autocorrelation\n",
    "if dw_stat < 2 or dw_stat > 2:\n",
    "    print(\"There is autocorrelation in the data, the model is likely non-linear\")\n",
    "else:\n",
    "    print(\"There is no autocorrelation in the data, the model is likely linear\")\n",
    "    \n",
    "# Define the model\n",
    "model =RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "df_train.to_csv('submission_to_submit7.csv', index=False)\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "df_train.to_csv('submission_to_submit8.csv', index=False)\n",
    "\n",
    "\n",
    "# Make predictions on the validation set\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_val, predictions)\n",
    "\n",
    "# Take the square root of the mean squared error to get the root mean squared error\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "# Calculate the R-squared score\n",
    "r2 = r2_score(y_val, predictions)\n",
    "\n",
    "# print the R2 score\n",
    "print(\"R2 score: \", r2)\n",
    "df_train.to_csv('submission_to_submit5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "5c9888da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficients:  [-0.18933836288699657, -0.34838970300314015, -0.19349113512366997, -0.29007117631367796, -0.20230714599546026, -0.4903296543807421]\n",
      "p-values:  [0.1248937474905164, 0.003863057621510686, 0.11668194878397109, 0.0172613760599387, 0.10062782983280501, 2.531412351949268e-05]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr = []\n",
    "p_value = []\n",
    "\n",
    "for i in range(X_train.shape[1]):\n",
    "    corr_i, p_value_i = pearsonr(X_train[:,i], y_train)\n",
    "    corr.append(corr_i)\n",
    "    p_value.append(p_value_i)\n",
    "\n",
    "print(\"Correlation coefficients: \", corr)\n",
    "print(\"p-values: \", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "a7ba37ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepa\\anaconda3\\envs\\Python35\\lib\\site-packages\\sklearn\\base.py:444: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('test_descriptors.csv')\n",
    "df_1=df_test['SMILES']\n",
    "df_test = df_test.drop(columns=[\"SMILES\",\"logP\",\"ring_count\"])\n",
    "# Extract the \"MW\" column\n",
    "MW = df_test[\"MW\"]\n",
    "\n",
    "# Min-Max normalization\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "MW_normalized = min_max_scaler.fit_transform(MW.values.reshape(-1,1))\n",
    "\n",
    "# Add the normalized column back to the dataframe\n",
    "df_test[\"MW\"] = MW_normalized\n",
    "# Extract the \"MW\" column\n",
    "TPSA = df_test[\"TPSA\"]\n",
    "\n",
    "# Min-Max normalization\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "TPSA_normalized = min_max_scaler.fit_transform(TPSA.values.reshape(-1,1))\n",
    "\n",
    "# Add the normalized column back to the dataframe\n",
    "df_test[\"TPSA\"] = TPSA_normalized\n",
    "test_predictions = model.predict(df_test)\n",
    "df_test['pIC50 (IC50 in microM)'] = test_predictions\n",
    "df_test = df_test[['pIC50 (IC50 in microM)']]\n",
    "# Merge the columns of the two dataframes\n",
    "df_test = pd.concat([df_1, df_test], axis=1)\n",
    "df_test.to_csv('missing_smiles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "b9905b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOO-Q2 score:  0.16556470127089237\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    return model\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "# Create an instance of the KFold()\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "# create a scoring function\n",
    "scorer = make_scorer(r2_score)\n",
    "\n",
    "# calculate the LOO-Q2 score\n",
    "loo_q2 = cross_val_score(model, X_train1, y_train1, cv=kfold, scoring=scorer)\n",
    "# print the LOO-Q2 score\n",
    "print(\"LOO-Q2 score: \", loo_q2.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72baad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
